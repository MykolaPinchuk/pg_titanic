{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52850930-9539-4beb-81cc-66476b59a4f6",
   "metadata": {},
   "source": [
    "### This is a script, building simple RF model for Titanic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16bfb71f-bb6b-411f-a128-5c1e61b6487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'My First Project'\n",
    "project_id = 'valid-heuristic-369117'\n",
    "regionn = 'us-west1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32a220d1-04c2-42fb-8bca-d564de61cc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Load libraries #\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os, time, warnings, optuna, pickle, joblib\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder, OrdinalEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV, train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, precision_recall_curve, auc\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from google.cloud import bigquery, storage\n",
    "\n",
    "pd.set_option('display.max_columns', 20)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load custom pre-processing functions:\n",
    "\n",
    "def fillna_mp_i1(df_train, df_test, df_pred, num_features, cat_features, num_fill='median', cat_fill='mode'):\n",
    "    \"\"\"This function speeds up filling missing values for 3 main datasets using different imputation methods.\n",
    "    Later may replace it with some subclass.\n",
    "    Example: fillna_mp_i1(X_train, X_test, X_pred, num_cols, cat_cols)\"\"\"\n",
    "    # set df_pred to None if it does not exist\n",
    "    if not ((cat_fill=='mode') and (num_fill=='median')):\n",
    "        print ('Imputation method not Implemented yet!')\n",
    "        return None\n",
    "    \n",
    "    df_train[num_features] = df_train[num_features].fillna(value=df_train[num_features].median())\n",
    "    df_test[num_features] = df_test[num_features].fillna(value=df_train[num_features].median())\n",
    "    df_train[cat_features] = df_train[cat_features].fillna(value=df_train[cat_features].mode().iloc[0])\n",
    "    df_test[cat_features] = df_test[cat_features].fillna(value=df_train[cat_features].mode().iloc[0])\n",
    "    if (df_pred is not None):\n",
    "        df_pred[num_features] = df_pred[num_features].fillna(value=df_train[num_features].median())\n",
    "        df_pred[cat_features] = df_pred[cat_features].fillna(value=df_train[cat_features].mode().iloc[0])\n",
    "    df_train[num_features+cat_features].count\n",
    "    \n",
    "    all_good = (\n",
    "    (np.prod(df_train[num_features+cat_features].shape)==df_train[num_features+cat_features].count().sum()) and \n",
    "    (np.prod(df_test[num_features+cat_features].shape) == df_test[num_features+cat_features].count().sum()) and \n",
    "    (np.prod(df_pred[num_features+cat_features].shape) == df_pred[num_features+cat_features].count().sum()))\n",
    "    if (all_good):\n",
    "        print('Missing values imputed successfully')\n",
    "    else:\n",
    "        print('There are still some missing values...')\n",
    "    \n",
    "def add_misDummy_mp_i1(df_train, df_test, df_pred, features):\n",
    "    \"\"\"This function creates new dummy columns for missing features.\n",
    "    Example: add_misDummy_mp_i1(X_train, X_test, X_pred, ['Age'])\"\"\"\n",
    "    # set df_pred to None if it does not exist\n",
    "    for feature_name in features:\n",
    "        misColName = 'mis'+feature_name\n",
    "        df_train.loc[df_train[feature_name].isnull(), misColName]=1\n",
    "        df_train.loc[df_train[feature_name].notnull(), misColName]=0\n",
    "        df_test.loc[df_test[feature_name].isnull(), misColName]=1\n",
    "        df_test.loc[df_test[feature_name].notnull(), misColName]=0\n",
    "        if (df_pred is not None):\n",
    "            df_pred.loc[df_pred[feature_name].isnull(), misColName]=1\n",
    "            df_pred.loc[df_pred[feature_name].notnull(), misColName]=0\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e582e58-ad0c-4982-8c0a-84a4afc9579d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 8) (418, 7)\n"
     ]
    }
   ],
   "source": [
    "# 1. Load data #\n",
    "\n",
    "time0 = time.time()\n",
    "\n",
    "os.chdir('/home/jupyter/projects_data/titanic')\n",
    "df = pd.read_csv('train.csv') \n",
    "\n",
    "df.drop(columns=['Name', 'Ticket', 'Cabin', 'PassengerId'],inplace=True)\n",
    "pred = pd.read_csv('test.csv')\n",
    "pred.drop(columns=['Name', 'Ticket', 'Cabin', 'PassengerId'],inplace=True)\n",
    "\n",
    "print(df.shape, pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "865174ee-c143-4bcd-9a33-848a88bd2b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical features:  ['Sex', 'Embarked'] numerical features:  ['Age2', 'Age', 'Parch', 'Fare', 'SibSp', 'Pclass']\n",
      "(712, 8) (179, 8) (712, 1) (418, 8)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 712 entries, 42 to 122\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Pclass    712 non-null    int64  \n",
      " 1   Sex       712 non-null    object \n",
      " 2   Age       570 non-null    float64\n",
      " 3   SibSp     712 non-null    int64  \n",
      " 4   Parch     712 non-null    int64  \n",
      " 5   Fare      712 non-null    float64\n",
      " 6   Embarked  710 non-null    object \n",
      " 7   Age2      570 non-null    float64\n",
      "dtypes: float64(3), int64(3), object(2)\n",
      "memory usage: 50.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# 2. EDA, adding features #\n",
    "\n",
    "df['Age2'] = df['Age']**2\n",
    "pred['Age2'] = pred['Age']**2\n",
    "\n",
    "# 3. Train-test split #\n",
    "\n",
    "train_y = df[['Survived']]\n",
    "train_x = df.drop(columns = ['Survived'])\n",
    "X_pred = pred.copy()\n",
    "\n",
    "cat_cols = ['Sex', 'Embarked']\n",
    "num_cols = list(set(train_x.columns)-set(cat_cols))\n",
    "\n",
    "print('categorical features: ', cat_cols, 'numerical features: ', num_cols)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size = 0.2, random_state=4)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, X_pred.shape)\n",
    "\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffd6796a-a6df-4c60-a9fb-7fedcd5b6cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values imputed successfully\n"
     ]
    }
   ],
   "source": [
    "# 4. Misisng values #\n",
    "\n",
    "add_misDummy_mp_i1(X_train, X_test, X_pred, ['Age'])\n",
    "\n",
    "fillna_mp_i1(X_train, X_test, X_pred, num_cols, cat_cols)\n",
    "\n",
    "cat_cols.extend(['misAge'])\n",
    "\n",
    "feature_transformer = ColumnTransformer([\n",
    "        (\"cat\", OneHotEncoder(sparse = False, handle_unknown=\"ignore\", drop='if_binary'), cat_cols)],\n",
    "        remainder = \"passthrough\"\n",
    "    )\n",
    "\n",
    "X_train = pd.DataFrame(feature_transformer.fit_transform(X_train), columns=feature_transformer.get_feature_names_out())\n",
    "X_test = pd.DataFrame(feature_transformer.transform(X_test), columns=feature_transformer.get_feature_names_out())\n",
    "X_pred = pd.DataFrame(feature_transformer.transform(X_pred), columns=feature_transformer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14974503-08fd-460f-9ec8-152f5b390150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF  {'max_depth': 5, 'max_features': 4, 'n_estimators': 100} \n",
      " 0.8553370786516854 0.8314118423222827 12.838726043701172\n",
      "XGB  {'colsample_bytree': 0.6, 'eta': 0.01, 'max_depth': 4, 'n_estimators': 250, 'subsample': 0.7} \n",
      " 0.8581460674157303 0.8386194952993569 33.143598318099976\n",
      "Out of Sample:\n",
      "RF  0.8379888268156425 0.7913865546218487\n",
      "XGB  0.8212290502793296 0.7829131652661064\n",
      "Total time  46.11894345283508\n",
      "Total time for training part:  46.119004249572754\n"
     ]
    }
   ],
   "source": [
    "# 6. Fit models #\n",
    "\n",
    "time1 = time.time()\n",
    "rf = RandomForestClassifier()\n",
    "param_grid = {'n_estimators':[100, 200], \n",
    "              'max_depth':[3, 4, 5, 6, 7], \n",
    "              'max_features':[4, 5, 6]}\n",
    "rfm = GridSearchCV(rf, param_grid, cv=2)\n",
    "rfm.fit(X_train, y_train)\n",
    "print('RF ', \n",
    "      rfm.best_params_, \n",
    "      '\\n',\n",
    "      accuracy_score(y_train, rfm.predict(X_train)), \n",
    "      roc_auc_score(y_train, rfm.predict(X_train)), time.time()-time1)\n",
    "\n",
    "time1 = time.time()\n",
    "xgb = XGBClassifier()\n",
    "# use 'gpu_hist' for more than 10,000 examples.\n",
    "param_grid = {'n_estimators':[150, 250], \n",
    "              'max_depth':[2, 3, 4], \n",
    "              'eta':[0.01, 0.02, 0.03, 0.04, 0.05, 0.06], \n",
    "              'subsample':[0.7],\n",
    "              'colsample_bytree':[0.6]}\n",
    "xgbm = GridSearchCV(xgb, param_grid, cv=2)\n",
    "xgbm.fit(X_train, y_train)\n",
    "print('XGB ', \n",
    "      xgbm.best_params_, \n",
    "      '\\n',\n",
    "      accuracy_score(y_train, xgbm.predict(X_train)), \n",
    "      roc_auc_score(y_train, xgbm.predict(X_train)), \n",
    "      time.time()-time1)\n",
    "\n",
    "\n",
    "# 7. model evaluation #\n",
    "\n",
    "print('Out of Sample:')\n",
    "print('RF ', \n",
    "      accuracy_score(y_test, rfm.predict(X_test)), \n",
    "      roc_auc_score(y_test, rfm.predict(X_test)))\n",
    "print('XGB ', \n",
    "      accuracy_score(y_test, xgbm.predict(X_test)), \n",
    "      roc_auc_score(y_test, xgbm.predict(X_test)))\n",
    "print('Total time ', time.time()-time0)\n",
    "\n",
    "print('Total time for training part: ', time.time() - time0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd93e71-29bb-4d1a-8c21-2f57d89093a5",
   "metadata": {},
   "source": [
    "The results are somewhat surprising. I have played for more than 1 hours with hyprparmeters and RF still usually beats XGB. \n",
    "If I do hyperparemter tuning rigorously (e.g., Optuna), xgb will probably beat RF eventually. But do not want to waste more time on this, given that thi is Prod script. So I use RF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6ad6f55-0032-4a70-b121-c9c7b3af0020",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat__Sex_male</th>\n",
       "      <th>cat__Embarked_C</th>\n",
       "      <th>cat__Embarked_Q</th>\n",
       "      <th>cat__Embarked_S</th>\n",
       "      <th>cat__misAge_1.0</th>\n",
       "      <th>remainder__Pclass</th>\n",
       "      <th>remainder__Age</th>\n",
       "      <th>remainder__SibSp</th>\n",
       "      <th>remainder__Parch</th>\n",
       "      <th>remainder__Fare</th>\n",
       "      <th>remainder__Age2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>812.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0000</td>\n",
       "      <td>3600.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.5500</td>\n",
       "      <td>1296.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.4667</td>\n",
       "      <td>812.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>812.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.9000</td>\n",
       "      <td>1600.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.2458</td>\n",
       "      <td>812.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>961.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.6958</td>\n",
       "      <td>3136.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>1056.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cat__Sex_male  cat__Embarked_C  cat__Embarked_Q  cat__Embarked_S  \\\n",
       "0              1.0              1.0              0.0              0.0   \n",
       "1              1.0              0.0              0.0              1.0   \n",
       "2              1.0              0.0              0.0              1.0   \n",
       "3              0.0              0.0              0.0              1.0   \n",
       "4              1.0              0.0              0.0              1.0   \n",
       "..             ...              ...              ...              ...   \n",
       "707            1.0              0.0              0.0              1.0   \n",
       "708            1.0              1.0              0.0              0.0   \n",
       "709            1.0              0.0              0.0              1.0   \n",
       "710            1.0              1.0              0.0              0.0   \n",
       "711            1.0              1.0              0.0              0.0   \n",
       "\n",
       "     cat__misAge_1.0  remainder__Pclass  remainder__Age  remainder__SibSp  \\\n",
       "0                1.0                3.0            28.5               0.0   \n",
       "1                0.0                2.0            60.0               1.0   \n",
       "2                0.0                3.0            36.0               1.0   \n",
       "3                1.0                3.0            28.5               3.0   \n",
       "4                1.0                1.0            28.5               0.0   \n",
       "..               ...                ...             ...               ...   \n",
       "707              0.0                3.0            40.0               1.0   \n",
       "708              1.0                3.0            28.5               1.0   \n",
       "709              0.0                2.0            31.0               0.0   \n",
       "710              0.0                1.0            56.0               0.0   \n",
       "711              0.0                2.0            32.5               1.0   \n",
       "\n",
       "     remainder__Parch  remainder__Fare  remainder__Age2  \n",
       "0                 0.0           7.8958           812.25  \n",
       "1                 1.0          39.0000          3600.00  \n",
       "2                 0.0          15.5500          1296.00  \n",
       "3                 1.0          25.4667           812.25  \n",
       "4                 0.0          30.0000           812.25  \n",
       "..                ...              ...              ...  \n",
       "707               4.0          27.9000          1600.00  \n",
       "708               1.0          15.2458           812.25  \n",
       "709               0.0          10.5000           961.00  \n",
       "710               0.0          30.6958          3136.00  \n",
       "711               0.0          30.0708          1056.25  \n",
       "\n",
       "[712 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1b7a0d3-8ea3-466f-ae98-3883d72a7785",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/jupyter/project_repos/pg_titanic/pg_titanic/titanic-app')\n",
    "\n",
    "artifact_filename_rf = 'rf_model.pkl'\n",
    "joblib.dump(rfm, artifact_filename_rf)\n",
    "\n",
    "model_bucket = 'gs://pmykola-projectsgcp-artifacts/titanic'\n",
    "storage_path = os.path.join(model_bucket, artifact_filename_rf)\n",
    "blob = storage.blob.Blob.from_string(storage_path, client=storage.Client(project=project_id))\n",
    "blob.upload_from_filename(os.getcwd()+'/'+artifact_filename_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fb26236-e119-4f70-b93d-f5141b5c3aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf [0]\n"
     ]
    }
   ],
   "source": [
    "file = open(artifact_filename_rf, \"rb\")\n",
    "trained_model = joblib.load(file)\n",
    "prediction = trained_model.predict([list(X_test.iloc[0,:])])\n",
    "print('rf', prediction)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m100",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
